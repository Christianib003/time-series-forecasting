{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e96fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /Users/testsolutions/Documents/school/year3/term2/time-series-forecasting/tsf-repo\n",
      "SRC exists: True\n",
      "sys.path[0]: /Users/testsolutions/Documents/school/year3/term2/time-series-forecasting/tsf-repo\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 — make `src/` importable in this notebook\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "\n",
    "# If this notebook lives in <ROOT>/notebooks, go to project root; else keep cwd\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "SRC = ROOT / \"src\"\n",
    "\n",
    "# Ensure src package structure exists (idempotent)\n",
    "SRC.mkdir(parents=True, exist_ok=True)\n",
    "(SRC / \"__init__.py\").touch(exist_ok=True)\n",
    "(SRC / \"models\").mkdir(parents=True, exist_ok=True)\n",
    "(SRC / \"models\" / \"__init__.py\").touch(exist_ok=True)\n",
    "\n",
    "# Ensure src/utils.py exists\n",
    "(SRC / \"utils.py\").touch(exist_ok=True)\n",
    "(SRC / \"config.py\").touch(exist_ok=True)\n",
    "(SRC / \"cv.py\").touch(exist_ok=True)\n",
    "(SRC / \"window.py\").touch(exist_ok=True)\n",
    "(SRC / \"scaling.py\").touch(exist_ok=True)\n",
    "(SRC / \"metrics.py\").touch(exist_ok=True)\n",
    "(SRC / \"models\" / \"lstm.py\").touch(exist_ok=True)\n",
    "\n",
    "# Put project ROOT (the directory that CONTAINS 'src') on sys.path\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "# Clear stale caches\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"SRC exists:\", SRC.exists())\n",
    "print(\"sys.path[0]:\", sys.path[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079f18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "# Verify src/utils.py contains the required functions\n",
    "assert (SRC / \"utils.py\").exists(), \"utils.py is missing in src directory\"\n",
    "\n",
    "from src.utils import seed_all, get_logger\n",
    "from src.config import DATA_INTERIM, OUTPUTS, MODELS_DIR\n",
    "from src.cv import make_blocked_folds, mask_for_range\n",
    "from src.window import make_windows\n",
    "from src.scaling import PerFoldScaler\n",
    "from src.metrics import rmse\n",
    "from src.models.lstm import build_lstm\n",
    "from src.features import add_target_lags\n",
    "\n",
    "\n",
    "\n",
    "seed_all(42)\n",
    "log = get_logger(\"LSTM-BL\")\n",
    "OUTPUTS.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "LOOKBACK = 168  # start with 168; we'll try 72 and 336 later\n",
    "BATCH = 64\n",
    "EPOCHS = 50\n",
    "PATIENCE = 8\n",
    "LR = 1e-3\n",
    "UNITS = 64\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "REC_DROPOUT = 0.0\n",
    "CLIPNORM = 1.0\n",
    "\n",
    "TARGET     = \"pm2_5\"\n",
    "LAGS       = (1, 24, 168)    # NEW: autoregressive features\n",
    "MAX_LAG    = max(LAGS)       # used to trim early rows lacking lag values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd0f16",
   "metadata": {},
   "source": [
    "## 2. Load data, feature list, folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "937d2de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 20\n",
      "first 10 features: ['DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir', 'cbwd_NW', 'cbwd_SE', 'cbwd_cv', 'hour']\n",
      "fold1: TRAIN 2010-01-02 00:00:00 → 2013-06-03 02:00:00 | VAL 2013-06-03 03:00:00 → 2013-07-02 03:00:00\n",
      "fold2: TRAIN 2010-01-02 00:00:00 → 2013-05-04 02:00:00 | VAL 2013-05-04 03:00:00 → 2013-06-02 03:00:00\n",
      "fold3: TRAIN 2010-01-02 00:00:00 → 2013-04-04 02:00:00 | VAL 2013-04-04 03:00:00 → 2013-05-03 03:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load interim set and keep train split\n",
    "df = pd.read_csv(DATA_INTERIM / \"clean.csv\", parse_dates=[\"datetime\"])\n",
    "train_df = df.query(\"split=='train'\").reset_index(drop=True)\n",
    "\n",
    "# Add target lags ONCE globally, then we’ll slice per fold\n",
    "train_df = add_target_lags(train_df, target=TARGET, lags=LAGS)\n",
    "\n",
    "# Build feature list (exclude time, ids, and raw target)\n",
    "EXCLUDE = {\"datetime\", \"split\", \"pm2.5\", \"pm2_5\", \"No\"}\n",
    "feature_cols = [c for c in train_df.columns if c not in EXCLUDE]\n",
    "print(\"n_features:\", len(feature_cols))\n",
    "print(\"first 10 features:\", feature_cols[:10])\n",
    "\n",
    "# Folds (blocked, using 30-day validation windows)\n",
    "folds = make_blocked_folds(train_df, \"datetime\", n_folds=3, val_days=30)\n",
    "for f in folds:\n",
    "    print(f\"{f.name}: TRAIN {f.train_start} → {f.train_end} | VAL {f.val_start} → {f.val_end}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffff2eb",
   "metadata": {},
   "source": [
    "### 3. Per-fold training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50a5a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - loss: 0.9125 - val_loss: 0.2224 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - loss: 0.3443 - val_loss: 0.1830 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - loss: 0.3123 - val_loss: 0.1653 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - loss: 0.2957 - val_loss: 0.1459 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 57ms/step - loss: 0.2851 - val_loss: 0.1402 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 73ms/step - loss: 0.2727 - val_loss: 0.1479 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 89ms/step - loss: 0.2618 - val_loss: 0.1515 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 81ms/step - loss: 0.2440 - val_loss: 0.1529 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 70ms/step - loss: 0.2364 - val_loss: 0.1533 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 68ms/step - loss: 0.2211 - val_loss: 0.1479 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 66ms/step - loss: 0.2161 - val_loss: 0.1508 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 77ms/step - loss: 0.2108 - val_loss: 0.1514 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 68ms/step - loss: 0.2098 - val_loss: 0.1457 - learning_rate: 5.0000e-04\n",
      "fold1 RMSE: 45.605\n",
      "Epoch 1/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 74ms/step - loss: 0.8189 - val_loss: 0.1437 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 70ms/step - loss: 0.3602 - val_loss: 0.1182 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 69ms/step - loss: 0.3276 - val_loss: 0.1149 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 71ms/step - loss: 0.3057 - val_loss: 0.1118 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 72ms/step - loss: 0.2807 - val_loss: 0.0995 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 71ms/step - loss: 0.2726 - val_loss: 0.0970 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 69ms/step - loss: 0.2563 - val_loss: 0.0927 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 68ms/step - loss: 0.2463 - val_loss: 0.0960 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 68ms/step - loss: 0.2355 - val_loss: 0.0964 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 65ms/step - loss: 0.2342 - val_loss: 0.0944 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 70ms/step - loss: 0.2229 - val_loss: 0.0880 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 70ms/step - loss: 0.2199 - val_loss: 0.0909 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 72ms/step - loss: 0.2226 - val_loss: 0.0937 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 71ms/step - loss: 0.2139 - val_loss: 0.0938 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 72ms/step - loss: 0.2172 - val_loss: 0.1063 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 70ms/step - loss: 0.1988 - val_loss: 0.0901 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 70ms/step - loss: 0.1965 - val_loss: 0.0957 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 70ms/step - loss: 0.1912 - val_loss: 0.0977 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 71ms/step - loss: 0.1888 - val_loss: 0.0932 - learning_rate: 5.0000e-04\n",
      "fold2 RMSE: 19.607\n",
      "Epoch 1/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 71ms/step - loss: 0.8378 - val_loss: 0.2721 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 82ms/step - loss: 0.3576 - val_loss: 0.2037 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 80ms/step - loss: 0.3300 - val_loss: 0.1870 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 93ms/step - loss: 0.3051 - val_loss: 0.1854 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 68ms/step - loss: 0.2858 - val_loss: 0.2022 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 83ms/step - loss: 0.2765 - val_loss: 0.2220 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 91ms/step - loss: 0.2610 - val_loss: 0.2244 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 74ms/step - loss: 0.2547 - val_loss: 0.2214 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 67ms/step - loss: 0.2369 - val_loss: 0.1738 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 69ms/step - loss: 0.2255 - val_loss: 0.1847 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 83ms/step - loss: 0.2251 - val_loss: 0.1912 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 89ms/step - loss: 0.2191 - val_loss: 0.2053 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 76ms/step - loss: 0.2212 - val_loss: 0.1787 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 87ms/step - loss: 0.2084 - val_loss: 0.2099 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 74ms/step - loss: 0.2069 - val_loss: 0.2317 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 68ms/step - loss: 0.2017 - val_loss: 0.2253 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 69ms/step - loss: 0.2021 - val_loss: 0.2117 - learning_rate: 2.5000e-04\n",
      "fold3 RMSE: 19.148\n",
      "CV RMSE mean±std: 28.120 ± 15.144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>rmse</th>\n",
       "      <th>model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fold1</td>\n",
       "      <td>45.604717</td>\n",
       "      <td>/Users/testsolutions/Documents/school/year3/te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fold2</td>\n",
       "      <td>19.607052</td>\n",
       "      <td>/Users/testsolutions/Documents/school/year3/te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fold3</td>\n",
       "      <td>19.147961</td>\n",
       "      <td>/Users/testsolutions/Documents/school/year3/te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold       rmse                                         model_path\n",
       "0  fold1  45.604717  /Users/testsolutions/Documents/school/year3/te...\n",
       "1  fold2  19.607052  /Users/testsolutions/Documents/school/year3/te...\n",
       "2  fold3  19.147961  /Users/testsolutions/Documents/school/year3/te..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "cv_rows = []\n",
    "histories = {}\n",
    "\n",
    "for f in folds:\n",
    "    # ---- slice fold windows\n",
    "    tr_mask = (train_df[\"datetime\"] >= f.train_start) & (train_df[\"datetime\"] <= f.train_end)\n",
    "    va_mask = (train_df[\"datetime\"] >= f.val_start)   & (train_df[\"datetime\"] <= f.val_end)\n",
    "\n",
    "    tr = train_df.loc[tr_mask].copy()\n",
    "    va = train_df.loc[va_mask].copy()\n",
    "\n",
    "    # ---- trim initial rows lacking lag values\n",
    "    tr = tr.iloc[MAX_LAG:].reset_index(drop=True)\n",
    "    va = va.iloc[MAX_LAG:].reset_index(drop=True)\n",
    "\n",
    "    # ---- targets (log1p on train; val true kept in original scale for scoring)\n",
    "    y_tr      = np.log1p(tr[TARGET].values.astype(\"float32\"))\n",
    "    y_va_true = va[TARGET].values.astype(\"float32\")\n",
    "\n",
    "    # ---- scale features per-fold on training slice only\n",
    "    scaler = PerFoldScaler()\n",
    "    X_tr = scaler.fit_transform(tr[feature_cols])\n",
    "    X_va = scaler.transform(va[feature_cols])\n",
    "\n",
    "    # ---- windowing (predict y_t from [t-L..t-1])\n",
    "    Xw_tr, yw_tr = make_windows(X_tr, y_tr, lookback=LOOKBACK)\n",
    "    # for val, we supply dummy y just to get shape; callbacks will use real val y below\n",
    "    Xw_va, _     = make_windows(X_va, np.log1p(y_va_true), lookback=LOOKBACK)\n",
    "\n",
    "    # ---- build model\n",
    "    model = build_lstm(\n",
    "        input_len=LOOKBACK, n_features=X_tr.shape[1],\n",
    "        units=UNITS, n_layers=N_LAYERS,\n",
    "        dropout=DROPOUT, recurrent_dropout=REC_DROPOUT,\n",
    "        clipnorm=CLIPNORM, lr=LR\n",
    "    )\n",
    "\n",
    "    # ---- callbacks: use the fold's TRUE validation window\n",
    "    ckpt_path = MODELS_DIR / f\"lstm_lb{LOOKBACK}_u{UNITS}_L{N_LAYERS}_{f.name}.keras\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=max(2, PATIENCE//2), min_lr=1e-5),\n",
    "        ModelCheckpoint(filepath=str(ckpt_path), monitor=\"val_loss\", save_best_only=True)\n",
    "    ]\n",
    "    y_va_log = np.log1p(y_va_true)[LOOKBACK:]  # align with Xw_va\n",
    "\n",
    "    history = model.fit(\n",
    "        Xw_tr, yw_tr,\n",
    "        validation_data=(Xw_va, y_va_log),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=False,  # time windows shouldn't be shuffled\n",
    "    )\n",
    "    histories[f.name] = history.history\n",
    "\n",
    "    # ---- predict & score on validation\n",
    "    y_va_pred_log = model.predict(Xw_va, verbose=0).reshape(-1)\n",
    "    y_va_pred     = np.expm1(y_va_pred_log)\n",
    "    y_va_true_aligned = y_va_true[LOOKBACK:]  # align lengths\n",
    "\n",
    "    fold_rmse = rmse(y_va_true_aligned, y_va_pred)\n",
    "    print(f\"{f.name} RMSE: {fold_rmse:.3f}\")\n",
    "\n",
    "    # also keep the path where best model was saved\n",
    "    cv_rows.append({\n",
    "        \"fold\": f.name,\n",
    "        \"rmse\": fold_rmse,\n",
    "        \"model_path\": str(ckpt_path)\n",
    "    })\n",
    "\n",
    "# ---- summary\n",
    "cv_df = pd.DataFrame(cv_rows)\n",
    "cv_mean = cv_df[\"rmse\"].mean()\n",
    "cv_std  = cv_df[\"rmse\"].std(ddof=1)\n",
    "print(f\"CV RMSE mean±std: {cv_mean:.3f} ± {cv_std:.3f}\")\n",
    "display(cv_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d55901",
   "metadata": {},
   "source": [
    "### 4. Log experiment to experiments/experiments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f94b4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged: /Users/testsolutions/Documents/school/year3/term2/time-series-forecasting/tsf-repo/outputs/experiments.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model</th>\n",
       "      <th>lookback</th>\n",
       "      <th>features</th>\n",
       "      <th>layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>recurrent_dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch</th>\n",
       "      <th>epochs</th>\n",
       "      <th>clipnorm</th>\n",
       "      <th>target_transform</th>\n",
       "      <th>lags</th>\n",
       "      <th>cv_rmse_mean</th>\n",
       "      <th>cv_rmse_std</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-21T17:00:48.504357+00:00</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>168</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>log1p</td>\n",
       "      <td>(1, 24, 168)</td>\n",
       "      <td>28.11991</td>\n",
       "      <td>15.144027</td>\n",
       "      <td>LSTM + target lags + true fold validation + ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp model  lookback  features  layers  units  \\\n",
       "0  2025-09-21T17:00:48.504357+00:00  LSTM       168        20       2     64   \n",
       "\n",
       "   dropout  recurrent_dropout optimizer     lr  batch  epochs  clipnorm  \\\n",
       "0      0.2                0.0      Adam  0.001     64      50       1.0   \n",
       "\n",
       "  target_transform          lags  cv_rmse_mean  cv_rmse_std  \\\n",
       "0            log1p  (1, 24, 168)      28.11991    15.144027   \n",
       "\n",
       "                                               notes  \n",
       "0  LSTM + target lags + true fold validation + ch...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "exp_row = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),  # timezone-aware\n",
    "    \"model\": \"LSTM\",\n",
    "    \"lookback\": LOOKBACK,\n",
    "    \"features\": len(feature_cols),\n",
    "    \"layers\": N_LAYERS,\n",
    "    \"units\": UNITS,\n",
    "    \"dropout\": DROPOUT,\n",
    "    \"recurrent_dropout\": REC_DROPOUT,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"lr\": LR,\n",
    "    \"batch\": BATCH,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"clipnorm\": CLIPNORM,\n",
    "    \"target_transform\": \"log1p\",\n",
    "    \"lags\": str(LAGS),\n",
    "    \"cv_rmse_mean\": round(float(cv_mean), 6),\n",
    "    \"cv_rmse_std\": round(float(cv_std), 6),\n",
    "    \"notes\": \"LSTM + target lags + true fold validation + checkpoint\"\n",
    "}\n",
    "\n",
    "exp_path = OUTPUTS / \"experiments.csv\"\n",
    "exp_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "if exp_path.exists():\n",
    "    pd.concat([pd.read_csv(exp_path), pd.DataFrame([exp_row])], ignore_index=True).to_csv(exp_path, index=False)\n",
    "else:\n",
    "    pd.DataFrame([exp_row]).to_csv(exp_path, index=False)\n",
    "\n",
    "print(\"Logged:\", exp_path)\n",
    "display(pd.read_csv(exp_path).tail())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
